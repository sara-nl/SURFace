{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required packages for processing\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pytz, time\n",
    "import matplotlib.pyplot as plt\n",
    "from multiprocessing import cpu_count\n",
    "from pandarallel import pandarallel\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from matplotlib.ticker import MultipleLocator, FixedLocator, LogLocator, NullFormatter, ScalarFormatter\n",
    "\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_parquet_to_df(name):\n",
    "    location_dataset = \"path to machine metric dataset\"\n",
    "    df = pd.read_parquet(os.path.join(location_dataset, name))\n",
    "    df = df.replace(-1, 0)\n",
    "    df = df.fillna(0)\n",
    "    df[\"dt\"] = pd.to_datetime(df.index, utc=True, unit=\"s\")\n",
    "    df[\"dt\"] = df[\"dt\"].dt.tz_convert(pytz.timezone('Europe/Amsterdam')).dt.tz_localize(None)\n",
    "    df = df.set_index(\"dt\")\n",
    "    df = df.sort_index()\n",
    "    df['Total']= df.sum(axis=1)\n",
    "    return(df)\n",
    "\n",
    "def preprocess_jobdata_to_df(name):\n",
    "    location_job_data_csv = \"path to workload\"\n",
    "    with open(os.path.join(location_job_data_csv, name),'r') as file:\n",
    "        filedata = file.read()\n",
    "        filedata = filedata.replace('None assigned','NoneAssigned')\n",
    "    with open(os.path.join(location_job_data_csv, str('processed_'+name)),'w') as file:\n",
    "        file.write(filedata)\n",
    "    jobdata = pd.read_fwf(os.path.join(location_job_data_csv, str('processed_'+name)), delimiter=r\"\\s+\", header=None)#, low_memory=False)\n",
    "    jobdata = jobdata.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)\n",
    "    jobdata = jobdata.rename(columns=jobdata.iloc[0]).drop(jobdata.index[0])\n",
    "    jobdata = jobdata.iloc[1:]\n",
    "    jobdata = jobdata.astype({\"ElapsedRaw\": int, \"CPUTimeRAW\": int, \"NCPUS\": int})\n",
    "    return(jobdata)\n",
    "\n",
    "def split_nodes(s):\n",
    "    if s is None or len(s) == 0:\n",
    "        return set()\n",
    "    \n",
    "    s = s.replace(\"\\r\\n\", \"\").replace(\"\\n\", \"\").replace(\"\\t\", \"\")\n",
    "\n",
    "    start = 0\n",
    "    index = 0\n",
    "    rack_chunks = []\n",
    "    in_bracket = False\n",
    "    while index < len(s):  # Separate them in parts like r12n[1-30,32] or r13n1\n",
    "        if s[index] == \"[\":\n",
    "            in_bracket = True\n",
    "        elif s[index] == \"]\":\n",
    "            in_bracket = False\n",
    "        elif s[index] == \",\" and not in_bracket:\n",
    "            rack_chunks.append(s[start: index])\n",
    "            start = index + 1\n",
    "        index += 1\n",
    "    rack_chunks.append(s[start: index])  # Add the last line\n",
    "    \n",
    "    node_names = set()\n",
    "\n",
    "    for rack_chunk in rack_chunks:\n",
    "        if \"[\" in rack_chunk:\n",
    "            prefix, postfix = rack_chunk.split(\"[\")\n",
    "            postfix = postfix[:-1]  # Remove the last bracket\n",
    "            nodes = postfix.split(\",\")\n",
    "            for node in nodes:\n",
    "                if \"-\" in node:\n",
    "                    start, end = node.split(\"-\")\n",
    "                    if not start.isnumeric() or not end.isnumeric():\n",
    "                        #print(\"???\", s)\n",
    "                        continue\n",
    "                    for i in range(int(start), int(end) + 1):\n",
    "                        node_names.add(\"{}{}\".format(prefix, i))\n",
    "                else:\n",
    "                    node_names.add(\"{}{}\".format(prefix, node))\n",
    "        else:\n",
    "            node_names.add(rack_chunk)\n",
    "\n",
    "    return node_names\n",
    "\n",
    "def calculate_perjob(row, data_type):\n",
    "    start = row[\"Start\"]\n",
    "    end = row[\"End\"]\n",
    "    nodes = row[\"NodeList\"]\n",
    "    selection = data_type.loc[start:end]\n",
    "\n",
    "    splitnodes = split_nodes(nodes)\n",
    "    intersection_nodes = set(selection.columns).intersection(splitnodes)\n",
    "\n",
    "    return selection[intersection_nodes].sum().sum()  # First is per column, second is summing the series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess data\n",
    "node_sockstat_TCP_mem = preprocess_parquet_to_df(\"node_sockstat_TCP_mem\")\n",
    "node_sockstat_UDP_mem = preprocess_parquet_to_df(\"node_sockstat_UDP_mem\")\n",
    "node_network_transmit_packets = preprocess_parquet_to_df(\"node_network_transmit_packets\")\n",
    "jobdata = preprocess_jobdata_to_df(\"jobdata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(node_sockstat_TCP_mem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if preprocessing was executed as expected\n",
    "filtered_jobdata = jobdata[(jobdata[\"Start\"] >= '2019-12-29 23:00:00') & (jobdata[\"Start\"] <= '2020-08-07 21:59:45')]\n",
    "filtered_jobdata = filtered_jobdata[(~filtered_jobdata[\"NodeList\"].str.contains(\"None\")) & (~filtered_jobdata[\"NodeList\"].str.contains(\"software\")) & (~filtered_jobdata[\"NodeList\"].str.contains(\"login\"))]\n",
    "filtered_jobdata[\"ElapsedRaw\"] = filtered_jobdata[\"ElapsedRaw\"]\n",
    "#print(filtered_jobdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_jobdata.to_pickle(\"filtered_jobdata.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"./cache/node_sockstat_TCP_mem_perjob.csv\"):\n",
    "    pandarallel.initialize(nb_workers=min(cpu_count(), 8), progress_bar=True)\n",
    "    node_sockstat_TCP_mem_perjob = filtered_jobdata\n",
    "    node_sockstat_TCP_mem_perjob[\"node_sockstat_TCP_mem\"] =  node_sockstat_TCP_mem_perjob.parallel_apply(calculate_perjob, axis=1, data_type=node_sockstat_TCP_mem)\n",
    "    node_sockstat_TCP_mem_perjob.to_csv('/var/scratch/lvs215/cache/node_sockstat_TCP_mem_perjob.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"./cache/node_sockstat_UDP_mem_perjob.csv\"):\n",
    "    pandarallel.initialize(nb_workers=min(cpu_count(), 8), progress_bar=True)\n",
    "    node_sockstat_UDP_mem_perjob = filtered_jobdata  # If cell above is executed, it will be essentially be node_sockstat_TCP_mem_perjob etc.\n",
    "    node_sockstat_UDP_mem_perjob[\"node_sockstat_UDP_mem\"] = node_sockstat_UDP_mem_perjob.parallel_apply(calculate_perjob, axis=1, data_type=node_sockstat_UDP_mem)\n",
    "    node_sockstat_UDP_mem_perjob.to_csv('/var/scratch/lvs215/cache/node_sockstat_UDP_mem_perjob.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"./cache/node_network_transmit_packets_perjob.csv\"):\n",
    "    pandarallel.initialize(nb_workers=min(cpu_count(), 10), progress_bar=True)\n",
    "    node_network_transmit_packets_perjob = filtered_jobdata\n",
    "    node_network_transmit_packets_perjob[\"node_network_transmit_packets\"] = node_network_transmit_packets_perjob.parallel_apply(calculate_perjob, axis=1, data_type=node_network_transmit_packets)\n",
    "    node_network_transmit_packets_perjob.to_csv('/var/scratch/lvs215/cache/node_network_transmit_packets_perjob.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude 0 values, since in this instance we only want to analyze jobs with traffic\n",
    "node_sockstat_TCP_mem_perjob = pd.read_csv('./cache/node_sockstat_TCP_mem_perjob.csv')  \n",
    "node_sockstat_TCP_mem_perjob = node_sockstat_TCP_mem_perjob[(node_sockstat_TCP_mem_perjob[\"node_sockstat_TCP_mem\"] > 0)]\n",
    "# Transform runtime to hours\n",
    "node_sockstat_TCP_mem_perjob[\"ElapsedRaw\"] = node_sockstat_TCP_mem_perjob[\"ElapsedRaw\"] * 60  # Back to minutes\n",
    "print(node_sockstat_TCP_mem_perjob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate averages for different time bins\n",
    "average_5min_TCP = (np.mean(node_sockstat_TCP_mem_perjob.loc[node_sockstat_TCP_mem_perjob[\"ElapsedRaw\"] < 5, \"node_sockstat_TCP_mem\"]))\n",
    "average_1hr_TCP = (np.mean(node_sockstat_TCP_mem_perjob.loc[(node_sockstat_TCP_mem_perjob[\"ElapsedRaw\"] >= 5) & (node_sockstat_TCP_mem_perjob[\"ElapsedRaw\"] < 60), \"node_sockstat_TCP_mem\"]))\n",
    "average_6hrs_TCP = (np.mean(node_sockstat_TCP_mem_perjob.loc[(node_sockstat_TCP_mem_perjob[\"ElapsedRaw\"] >= 60) & (node_sockstat_TCP_mem_perjob[\"ElapsedRaw\"] < 360), \"node_sockstat_TCP_mem\"]))\n",
    "average_1day_TCP = (np.mean(node_sockstat_TCP_mem_perjob.loc[(node_sockstat_TCP_mem_perjob[\"ElapsedRaw\"] >= 360) & (node_sockstat_TCP_mem_perjob[\"ElapsedRaw\"] < 1440), \"node_sockstat_TCP_mem\"]))\n",
    "average_1to5days_TCP = (np.mean(node_sockstat_TCP_mem_perjob.loc[(node_sockstat_TCP_mem_perjob[\"ElapsedRaw\"] >= 1440), \"node_sockstat_TCP_mem\"]))\n",
    "print(\"mean_5min\",average_5min_TCP)\n",
    "print(\"mean_1hr\",average_1hr_TCP)\n",
    "print(\"mean_6hrs\",average_6hrs_TCP)\n",
    "print(\"mean_1day\",average_1day_TCP)\n",
    "print(\"mean_1to5days\",average_1to5days_TCP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results\n",
    "cat = ['<5 minutes', '<1 hour', '<6 hours', '<1 day', '1 to 5 days']\n",
    "vals = [average_5min_TCP, average_1hr_TCP, average_6hrs_TCP, average_1day_TCP, average_1to5days_TCP]\n",
    "\n",
    "fig = plt.figure(figsize=(11, 5))\n",
    "plt.yscale(\"symlog\")\n",
    "plt.ylim(bottom=1)\n",
    "plt.ylim(top=10**5.8)\n",
    "plt.locator_params(axis='y', numticks=12)\n",
    "plt.bar(cat, vals, width=1, edgecolor=\"black\", color=\"lightcoral\")\n",
    "plt.xlabel(\"Job duration - Each previous category is excluded in the next\")\n",
    "plt.ylabel(\"Mean node_sockstat_TCP_mem\")\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"TCP_mem_job_duration.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude 0 values, since in this instance we only want to analyze jobs with traffic\n",
    "node_sockstat_UDP_mem_perjob = pd.read_csv('./cache/node_sockstat_UDP_mem_perjob.csv')  \n",
    "node_sockstat_UDP_mem_perjob = node_sockstat_UDP_mem_perjob[(node_sockstat_UDP_mem_perjob[\"node_sockstat_UDP_mem\"] > 0)]\n",
    "# Transform runtime to hours\n",
    "node_sockstat_UDP_mem_perjob[\"ElapsedRaw\"] = node_sockstat_UDP_mem_perjob[\"ElapsedRaw\"] * 60  # Back to minutes\n",
    "print(node_sockstat_UDP_mem_perjob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate averages for different time bins\n",
    "average_5min_UDP = (np.mean(node_sockstat_UDP_mem_perjob.loc[node_sockstat_UDP_mem_perjob[\"ElapsedRaw\"] < 5, \"node_sockstat_UDP_mem\"]))\n",
    "average_1hr_UDP = (np.mean(node_sockstat_UDP_mem_perjob.loc[(node_sockstat_UDP_mem_perjob[\"ElapsedRaw\"] >= 5) & (node_sockstat_UDP_mem_perjob[\"ElapsedRaw\"] < 60), \"node_sockstat_UDP_mem\"]))\n",
    "average_6hrs_UDP = (np.mean(node_sockstat_UDP_mem_perjob.loc[(node_sockstat_UDP_mem_perjob[\"ElapsedRaw\"] >= 60) & (node_sockstat_UDP_mem_perjob[\"ElapsedRaw\"] < 360), \"node_sockstat_UDP_mem\"]))\n",
    "average_1day_UDP = (np.mean(node_sockstat_UDP_mem_perjob.loc[(node_sockstat_UDP_mem_perjob[\"ElapsedRaw\"] >= 360) & (node_sockstat_UDP_mem_perjob[\"ElapsedRaw\"] < 1440), \"node_sockstat_UDP_mem\"]))\n",
    "average_1to5days_UDP = (np.mean(node_sockstat_UDP_mem_perjob.loc[(node_sockstat_UDP_mem_perjob[\"ElapsedRaw\"] >= 1440), \"node_sockstat_UDP_mem\"]))\n",
    "print(\"mean_5min\",average_5min_UDP)\n",
    "print(\"mean_1hr\",average_1hr_UDP)\n",
    "print(\"mean_6hrs\",average_6hrs_UDP)\n",
    "print(\"mean_1day\",average_1day_UDP)\n",
    "print(\"mean_1to5days\",average_1to5days_UDP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results\n",
    "cat = ['<5 minutes', '<1 hour', '<6 hours', '<1 day', '1 to 5 days']\n",
    "vals = [average_5min_UDP, average_1hr_UDP, average_6hrs_UDP, average_1day_UDP, average_1to5days_UDP]\n",
    "\n",
    "fig = plt.figure(figsize=(11, 5))\n",
    "plt.yscale(\"symlog\")\n",
    "plt.ylim(bottom=1)\n",
    "plt.ylim(top=10**6.8)\n",
    "plt.locator_params(axis='y', numticks=12)\n",
    "plt.bar(cat, vals, width=1, edgecolor=\"black\", color=\"lightcoral\")\n",
    "plt.xlabel(\"Job duration - Each previous category is excluded in the next\")\n",
    "plt.ylabel(\"Mean node_sockstat_UDP_mem\")\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"UDP_mem_job_duration.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude 0 values, since in this instance we only want to analyze jobs with traffic\n",
    "node_network_transmit_packets_perjob = pd.read_csv('./cache/node_network_transmit_packets_perjob.csv')  \n",
    "node_network_transmit_packets_perjob = node_network_transmit_packets_perjob[(node_network_transmit_packets_perjob[\"node_network_transmit_packets\"] > 0)]\n",
    "# Transform runtime to hours\n",
    "node_network_transmit_packets_perjob[\"ElapsedRaw\"] = node_network_transmit_packets_perjob[\"ElapsedRaw\"] / 3600  # Back to minutes\n",
    "print(node_network_transmit_packets_perjob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate averages for different time bins\n",
    "average_5min_transmit = (np.mean(node_network_transmit_packets_perjob.loc[node_network_transmit_packets_perjob[\"ElapsedRaw\"] < 5, \"node_network_transmit_packets\"]))\n",
    "average_1hr_transmit = (np.mean(node_network_transmit_packets_perjob.loc[(node_network_transmit_packets_perjob[\"ElapsedRaw\"] >= 5) & (node_network_transmit_packets_perjob[\"ElapsedRaw\"] < 60), \"node_network_transmit_packets\"]))\n",
    "average_6hrs_transmit = (np.mean(node_network_transmit_packets_perjob.loc[(node_network_transmit_packets_perjob[\"ElapsedRaw\"] >= 60) & (node_network_transmit_packets_perjob[\"ElapsedRaw\"] < 360), \"node_network_transmit_packets\"]))\n",
    "average_1day_transmit = (np.mean(node_network_transmit_packets_perjob.loc[(node_network_transmit_packets_perjob[\"ElapsedRaw\"] >= 360) & (node_network_transmit_packets_perjob[\"ElapsedRaw\"] < 1440), \"node_network_transmit_packets\"]))\n",
    "average_1to5days_transmit = (np.mean(node_network_transmit_packets_perjob.loc[(node_network_transmit_packets_perjob[\"ElapsedRaw\"] >= 1440), \"node_network_transmit_packets\"]))\n",
    "print(\"mean_5min\",average_5min_transmit)\n",
    "print(\"mean_1hr\",average_1hr_transmit)\n",
    "print(\"mean_6hrs\",average_6hrs_transmit)\n",
    "print(\"mean_1day\",average_1day_transmit)\n",
    "print(\"mean_1to5days\",average_1to5days_transmit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results\n",
    "cat = ['<5 minutes', '<1 hour', '<6 hours', '<1 day', '1 to 5 days']\n",
    "vals = [average_5min_transmit, average_1hr_transmit, average_6hrs_transmit, average_1day_transmit, average_1to5days_transmit]\n",
    "\n",
    "fig = plt.figure(figsize=(11, 5))\n",
    "plt.yscale(\"symlog\")\n",
    "plt.ylim(bottom=1)\n",
    "plt.ylim(top=10**14.2)\n",
    "plt.locator_params(axis='y', numticks=12)\n",
    "plt.bar(cat, vals, width=1, edgecolor=\"black\", color=\"lightcoral\")\n",
    "plt.xlabel(\"Job duration - Each previous category is excluded in the next\")\n",
    "plt.ylabel(\"Mean transmitted packets\")\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"node_network_transmit_packets_job_duration.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate scatterplot\n",
    "plot_df = node_network_transmit_packets_perjob.copy()\n",
    "# plot_df[\"ElapsedRaw\"] /= 60\n",
    "fig, ax = plt.subplots(figsize=(11, 5))\n",
    "ax.set_xlim(-1, 121)\n",
    "#ax.scatter(node_network_transmit_packets_perjob[\"ElapsedRaw\"],\n",
    "#            node_network_transmit_packets_perjob[\"node_network_transmit_packets\"], marker='o', color=\"lightcoral\")\n",
    "sns.regplot(x=\"ElapsedRaw\", y=\"node_network_transmit_packets\", \n",
    "            data=plot_df, \n",
    "            scatter=True,\n",
    "            fit_reg=True,\n",
    "            ax=ax,\n",
    "            marker='o',\n",
    "            color=\"lightcoral\",\n",
    "            line_kws={\"color\": \"steelblue\", \"label\": \"Linear model fit\"},\n",
    "            scatter_kws={\"rasterized\": True})\n",
    "\n",
    "#p = p.reset_index().rename(columns={'index': 'hour'})\n",
    "plot_df['ElapsedRaw'] = plot_df['ElapsedRaw'].astype(np.int)\n",
    "p95_data = plot_df.groupby(\"ElapsedRaw\")['node_network_transmit_packets'].quantile(.95)\n",
    "ax.plot(p95_data.index, p95_data, color=\"black\", linestyle=\"dashed\", label=\"$95^{th}$ percentile\")\n",
    "\n",
    "ax.get_yaxis().set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "ax.yaxis.get_offset_text().set_visible(False)\n",
    "fig.tight_layout()\n",
    "\n",
    "ax.set_xlabel(\"Job Duration [Hour]\", fontsize=18)\n",
    "ax.set_ylabel(\"Transmitted Packets ({})\".format(ax.get_yaxis().get_major_formatter().get_offset()), fontsize=20)  # Based on https://stackoverflow.com/a/45766598\n",
    "\n",
    "ax.tick_params(axis='both', which='major', labelsize=14)\n",
    "ax.tick_params(axis='both', which='minor', labelsize=14)\n",
    "#ax.get_xaxis().get_offset_text().set_size(14)\n",
    "ax.get_yaxis().get_offset_text().set_size(12)\n",
    "\n",
    "ax.legend(prop={\"size\": 14}, loc=\"upper left\")\n",
    "fig.tight_layout()\n",
    "\n",
    "date_time = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "fig.savefig(f\"node_network_transmit_packets_job_scatter_{date_time}.pdf\", bbox_inches = \"tight\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = node_network_transmit_packets_perjob.copy()\n",
    "#p = p.reset_index().rename(columns={'index': 'hour'})\n",
    "p['ElapsedRaw'] = p['ElapsedRaw'].astype(np.int)\n",
    "p.groupby(\"ElapsedRaw\")['node_network_transmit_packets'].quantile(.95)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del p"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
