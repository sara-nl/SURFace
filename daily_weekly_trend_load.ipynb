{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. Koalas will set it for you but it does not work if there is a Spark context already launched.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pytz\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "import pyarrow.parquet as pq\n",
    "from plotnine import *\n",
    "import calendar\n",
    "import numpy as np\n",
    "import databricks.koalas as ks \n",
    "import seaborn as sns\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = \"path to machine metric dataset\"\n",
    "\n",
    "loads = [\n",
    "    ('load1', 'node_load1'),\n",
    "    ('load5', 'node_load5'),\n",
    "    ('load15', 'node_load15'),\n",
    "    ('load1ML', 'node_load1')\n",
    "]\n",
    "\n",
    "gpu_nodes = {\n",
    "    \"r28n1\", \"r28n2\", \"r28n3\", \"r28n4\", \"r28n5\",\n",
    "    \"r29n1\", \"r29n2\", \"r29n3\", \"r29n4\", \"r29n5\",\n",
    "    \"r30n1\", \"r30n2\", \"r30n3\", \"r30n4\", \"r30n5\", \"r30n6\", \"r30n7\",\n",
    "    \"r31n1\", \"r31n2\", \"r31n3\", \"r31n4\", \"r31n5\", \"r31n6\"\n",
    "    \"r32n1\", \"r32n2\", \"r32n3\", \"r32n4\", \"r32n5\", \"r32n6\", \"r32n7\",\n",
    "    \"r33n2\", \"r33n3\", \"r33n5\", \"r33n6\",\n",
    "    \"r34n1\", \"r34n2\", \"r34n3\", \"r34n4\", \"r34n5\", \"r34n6\", \"r34n7\",\n",
    "    \"r35n1\", \"r35n2\", \"r35n3\", \"r35n4\", \"r35n5\",\n",
    "    \"r36n1\", \"r36n2\", \"r36n3\", \"r36n4\", \"r36n5\",\n",
    "    \"r38n1\", \"r38n2\", \"r38n3\", \"r38n4\", \"r38n5\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(data_root + 'node_load1')\n",
    "df = df.stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>load1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th>node</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1577833200</th>\n",
       "      <th>r1899n7</th>\n",
       "      <td>3.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r1899n1899</th>\n",
       "      <td>16.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r1899n1898</th>\n",
       "      <td>16.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r1899n1897</th>\n",
       "      <td>15.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r1899n1896</th>\n",
       "      <td>16.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1585864785</th>\n",
       "      <th>r1379n7</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r1379n4</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r1379n5</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r1379n2</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r1379n3</th>\n",
       "      <td>36.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178738560 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       load1\n",
       "time       node             \n",
       "1577833200 r1899n7      3.44\n",
       "           r1899n1899  16.00\n",
       "           r1899n1898  16.00\n",
       "           r1899n1897  15.82\n",
       "           r1899n1896  16.00\n",
       "...                      ...\n",
       "1585864785 r1379n7      0.00\n",
       "           r1379n4      0.00\n",
       "           r1379n5      0.00\n",
       "           r1379n2      0.00\n",
       "           r1379n3     36.00\n",
       "\n",
       "[178738560 rows x 1 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.index.names = ['time', 'node']\n",
    "df = df.rename(\"load1\").to_frame()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "color = ['lightcoral', 'steelblue', 'yellowgreen', 'orchid']\n",
    "#marker = ['o', '^', 's', '+']\n",
    "hatch = ['', '/', '\\\\', '+']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(11,5))\n",
    "\n",
    "index = 0\n",
    "barWidth = 0.2\n",
    "offset = [-0.3, -0.1, 0.1, 0.3]\n",
    "df = None\n",
    "\n",
    "for load, folder_name in loads:\n",
    "    \n",
    "    cach_file = os.path.join(\"./cache\", f\"loads_diurnal_hourly_cache_{load}.npy\")\n",
    "    # os.remove(cach_file)  # Trash the cache?\n",
    "    \n",
    "    if not os.path.isfile(cach_file):\n",
    "        df = pd.read_parquet(data_root + folder_name)\n",
    "\n",
    "        if load == \"load1ML\":  # Only keep ML nodes\n",
    "            df = df[set(df.columns).intersection(gpu_nodes)]\n",
    "        \n",
    "        # Pivot all columns so that it becomes a multi-index of (time, node).\n",
    "        df = df.stack()\n",
    "        # Set the names of the multi-index\n",
    "        df.index.names = ['time', 'node']\n",
    "        # Change the series name to the load name and then make it a dataframe\n",
    "        df = df.rename(load).to_frame()\n",
    "\n",
    "        # Drop all rows that do not feature at least one value >= 0\n",
    "        df = df.loc[(df >= 0).any(axis=1)]\n",
    "\n",
    "        df.reset_index(inplace=True)\n",
    "        df[\"dt\"] = pd.to_datetime(df['time'], utc=True, unit=\"s\")\n",
    "        # Convert everything into localized Amsterdam time and then drop the timezone info again\n",
    "        # dropping it is required to save the parquet file.\n",
    "        df[\"dt\"] = df[\"dt\"].dt.tz_convert(pytz.timezone('Europe/Amsterdam')).dt.tz_localize(None)\n",
    "        # Get hour of day and day columns to plot\n",
    "        df[\"hour_of_day\"] = df[\"dt\"].dt.hour\n",
    "\n",
    "        yerr_vals = df.groupby(\"hour_of_day\")[load].std()\n",
    "        df = df.groupby(\"hour_of_day\").mean()\n",
    "        x_vals = np.arange(len(df[load])) + offset[index]\n",
    "        y_vals = df[load]\n",
    "        \n",
    "        with open(cach_file, 'wb') as cache_file:\n",
    "            np.save(cache_file, x_vals)\n",
    "            np.save(cache_file, y_vals)\n",
    "            np.save(cache_file, yerr_vals)\n",
    "    else:\n",
    "        with open(cach_file, 'rb') as cache_file:\n",
    "            x_vals = np.load(cache_file)\n",
    "            y_vals = np.load(cache_file)\n",
    "            yerr_vals = np.load(cache_file)\n",
    "    \n",
    "    negative_direction_values = np.zeros(len(yerr_vals))  # We create a 2d array to make sure matplotlib does not create downwards errorbars\n",
    "    label = load\n",
    "    if label == \"load1ML\":\n",
    "        label = \"load1 ML\"\n",
    "    ax.bar(x_vals, y_vals, yerr=[negative_direction_values, yerr_vals], edgecolor='black', color=color[index], hatch=hatch[index], label=label, width=barWidth, capsize=3)\n",
    "    index += 1\n",
    "    \n",
    "\n",
    "# Add the GPU nodes to it\n",
    "\n",
    "ax.set_xlim(left=-1, right=24)\n",
    "ax.set_ylim(bottom=0, top=100)\n",
    "ax.set_xlabel(\"Hour of Day\", fontsize=20)\n",
    "ax.set_ylabel(\"Load\", fontsize=20)\n",
    "ax.tick_params(axis='both', which='major', labelsize=18)\n",
    "ax.tick_params(axis='both', which='minor', labelsize=16)\n",
    "ax.legend(ncol=len(color), prop={\"size\": 14}, bbox_to_anchor=(0.5, 1.15), loc=9)\n",
    "fig.tight_layout()\n",
    "\n",
    "date_time = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "\n",
    "fig.savefig(f\"loads_diurnal_hourly_{date_time}.pdf\")\n",
    "\n",
    "\n",
    "del fig\n",
    "del ax\n",
    "if df is not None: del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "color = ['lightcoral', 'steelblue', 'yellowgreen']\n",
    "#marker = ['o', '^', 's']\n",
    "hatch = ['', '/', '\\\\']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(11,5))\n",
    "\n",
    "index = 0\n",
    "offset = [-0.3, 0, 0.3]\n",
    "df = None\n",
    "\n",
    "for load, folder_name in loads:\n",
    "    \n",
    "    cach_file = os.path.join(\"./cache\", f\"loads_daily_cache_{load}.npy\")\n",
    "    \n",
    "    if not os.path.isfile(cach_file):\n",
    "        df = pd.read_parquet(data_root + folder_name)\n",
    "\n",
    "        # Pivot all columns so that it becomes a multi-index of (time, node).\n",
    "        df = df.stack()\n",
    "        # Set the names of the multi-index\n",
    "        df.index.names = ['time', 'node']\n",
    "        # Change the series name to the load name and then make it a dataframe\n",
    "        df = df.rename(load).to_frame()\n",
    "\n",
    "        # Drop all rows that do not feature at least one value >= 0\n",
    "        df = df[(df >= 0).any(axis=1)]\n",
    "\n",
    "        df.reset_index(inplace=True)\n",
    "        df[\"dt\"] = pd.to_datetime(df['time'], utc=True, unit=\"s\")\n",
    "        # Convert everything into localized Amsterdam time and then drop the timezone info again\n",
    "        # dropping it is required to save the parquet file.\n",
    "        df[\"dt\"] = df[\"dt\"].dt.tz_convert(pytz.timezone('Europe/Amsterdam')).dt.tz_localize(None)\n",
    "        # Get hour of day and day columns to plot\n",
    "    #     df[\"hour_of_day\"] = df[\"dt\"].dt.hour\n",
    "        df[\"day\"] = df[\"dt\"].apply(lambda x : x.weekday())\n",
    "\n",
    "        yerr_vals = df.groupby(\"day\")[load].std()\n",
    "\n",
    "        df = df.groupby(\"day\").mean()\n",
    "        x_vals = np.arange(len(df[load])) + offset[index]\n",
    "        y_vals = df[load]\n",
    "\n",
    "        with open(cach_file, 'wb') as cache_file:\n",
    "            np.save(cache_file, x_vals)\n",
    "            np.save(cache_file, y_vals)\n",
    "            np.save(cache_file, yerr_vals)\n",
    "    else:\n",
    "        with open(cach_file, 'rb') as cache_file:\n",
    "            x_vals = np.load(cache_file)\n",
    "            y_vals = np.load(cache_file)\n",
    "            yerr_vals = np.load(cache_file)\n",
    "    \n",
    "    negative_direction_values = np.zeros(len(yerr_vals))  # We create a 2d array to make sure matplotlib does not create downwards errorbars\n",
    "    ax.bar(x_vals, y_vals, yerr=[negative_direction_values, yerr_vals], edgecolor='black', color=color[index], hatch=hatch[index], label=load, width=barWidth, capsize=3)\n",
    "    index += 1\n",
    "\n",
    "ax.set_xlim(left=-1)\n",
    "ax.set_ylim(bottom=0, top=100)\n",
    "ax.set_xticks(list(np.arange(7)))\n",
    "ax.set_xticklabels(['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun'])\n",
    "ax.set_xlabel(\"Day of Week\", fontsize=20)\n",
    "ax.set_ylabel(\"Load\", fontsize=20)\n",
    "ax.tick_params(axis='both', which='major', labelsize=18)\n",
    "ax.tick_params(axis='both', which='minor', labelsize=16)\n",
    "ax.legend(ncol=len(color), prop={\"size\": 14}, bbox_to_anchor=(0.5, 1.15), loc=9)\n",
    "fig.tight_layout()\n",
    "\n",
    "date_time = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "fig.savefig(f\"loads_diurnal_daily_{date_time}.pdf\")\n",
    "\n",
    "del fig\n",
    "del ax\n",
    "if df: del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-240d39c2b091>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dt\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dt\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my_vals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "print(df[\"dt\"].min(), df[\"dt\"].max())\n",
    "print(len(df), len(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.314455323251899 7.355852748915351\n"
     ]
    }
   ],
   "source": [
    " with open('./cache/loads_diurnal_hourly_cache_load1ML.npy', 'rb') as cache_file:\n",
    "    x_vals = np.load(cache_file)\n",
    "    y_vals = np.load(cache_file)\n",
    "    yerr_vals = np.load(cache_file)\n",
    "print(y_vals.min(), y_vals.max())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# First, compute the average for the same hours per node, then the mean across all nodes\n",
    "load1_per_node_per_hour = df.groupby(\"hour_of_day\").mean()\n",
    "load1_per_hour = load1_per_node_per_hour.mean(axis=1).reset_index()\n",
    "load1_per_hour.columns = [\"hour_of_day\", \"load\"]\n",
    "print(load1_per_hour.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# This cell plots the average across all nodes.\n",
    "plt = ggplot(load1_per_hour) +\\\n",
    "    theme_light(base_size=16) +\\\n",
    "    theme(legend_title=element_text(size=0, alpha=0),\n",
    "                       legend_box_spacing=0.1,\n",
    "                       legend_box_margin=0,\n",
    "                       legend_margin=0,\n",
    "          legend_position=(0.51, 0.7),\n",
    "          legend_direction=\"horizontal\",\n",
    "          legend_key=element_blank(),\n",
    "          legend_background=element_rect(fill=(0,0,0,0))) +\\\n",
    "    guides(color=guide_legend(ncol=3)) +\\\n",
    "    geom_line(aes(x=\"hour_of_day\", y=\"load\")) +\\\n",
    "    geom_point(aes(x=\"hour_of_day\", y=\"load\"), size=3) +\\\n",
    "    ylim(0,None) +\\\n",
    "    xlab(\"Hour of day\") +\\\n",
    "    ylab(\"Avg. load1 across all nodes\")\n",
    "\n",
    "plt.save(\"load1_per_hour.pdf\")\n",
    "plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# First, compute the average for the same hours per node, then the mean across all nodes\n",
    "load1_per_node_per_day = df.groupby(\"day\").mean()\n",
    "load1_per_day = load1_per_node_per_day.mean(axis=1).reset_index()\n",
    "load1_per_day.columns = [\"day\", \"load\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt = ggplot(load1_per_day) +\\\n",
    "    theme_light(base_size=16) +\\\n",
    "    theme(legend_title=element_text(size=0, alpha=0),\n",
    "                       legend_box_spacing=0.1,\n",
    "                       legend_box_margin=0,\n",
    "                       legend_margin=0,\n",
    "          legend_position=(0.51, 0.7),\n",
    "          legend_direction=\"horizontal\",\n",
    "          legend_key=element_blank(),\n",
    "          legend_background=element_rect(fill=(0,0,0,0))) +\\\n",
    "    guides(color=guide_legend(ncol=3)) +\\\n",
    "    geom_line(aes(x=\"day\", y=\"load\")) +\\\n",
    "    geom_point(aes(x=\"day\", y=\"load\"), size=3) +\\\n",
    "    ylim(0,None) +\\\n",
    "    xlab(\"Day in Week (0=Monday, 6=Sunday)\") +\\\n",
    "    ylab(\"Avg. load1 across all nodes\")\n",
    "\n",
    "plt.save(\"load1_per_day.pdf\")\n",
    "plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Make bins of 15 minutes using resample and then create a sliding window so that for every 15 minutes we get the mean load.\n",
    "# bin_df = df.copy()\n",
    "# bin_df.index = pd.to_datetime(bin_df.index, unit=\"s\")\n",
    "# # Bin per 15 minute and create a sliding window of 1 hour.\n",
    "# # We take the right timestamp of the bin as this is the current time when measuring the mean.\n",
    "# bin_df = bin_df.resample(\"15min\", label='right').mean().rolling('1h').mean()\n",
    "# bin_df = bin_df.dropna(how=\"all\")  # Remove all rows with only NaN values\n",
    "\n",
    "# # IMPORTANT: as we took all right labels of each bin, the hour_of_day and day themselves are now incorrect, \n",
    "# # as all timestamps effectively shifted by 15 minutens. We need to recompute them.\n",
    "# bin_df[\"dt\"] = pd.to_datetime(bin_df.index, unit=\"s\")  # No need to convert time timezones again, this was already done!\n",
    "# bin_df[\"hour_of_day\"] = bin_df[\"dt\"].dt.hour\n",
    "# bin_df[\"day\"] = bin_df[\"dt\"].apply(lambda x : x.weekday())\n",
    "\n",
    "# bin_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load1_per_node_per_hour = bin_df.groupby(\"hour_of_day\").mean()\n",
    "# load1_per_hour = load1_per_node_per_hour.mean(axis=1).reset_index()\n",
    "# load1_per_hour.columns = [\"hour_of_day\", \"load\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell plots the average across all nodes per 15m using a rollowing window of 1 hour\n",
    "# plt = ggplot(load1_per_hour) +\\\n",
    "#     theme_light(base_size=16) +\\\n",
    "#     theme(legend_title=element_text(size=0, alpha=0),\n",
    "#                        legend_box_spacing=0.1,\n",
    "#                        legend_box_margin=0,\n",
    "#                        legend_margin=0,\n",
    "#           legend_position=(0.51, 0.7),\n",
    "#           legend_direction=\"horizontal\",\n",
    "#           legend_key=element_blank(),\n",
    "#           legend_background=element_rect(fill=(0,0,0,0))) +\\\n",
    "#     guides(color=guide_legend(ncol=3)) +\\\n",
    "#     geom_line(aes(x=\"hour_of_day\", y=\"load\")) +\\\n",
    "#     geom_point(aes(x=\"hour_of_day\", y=\"load\"), size=3) +\\\n",
    "#     ylim(0,None) +\\\n",
    "#     xlab(\"Hour of day\") +\\\n",
    "#     ylab(\"Avg. load1 across all nodes\")\n",
    "\n",
    "plt = ggplot(load1_per_hour, aes(x=\"hour_of_day\", y=\"load\")) +\\\n",
    "    theme_light(base_size=16) +\\\n",
    "    theme(axis_text_x = element_text(angle = 45)) +\\\n",
    "    geom_bar(stat = \"identity\") +\\\n",
    "    ylim(0,None) +\\\n",
    "    xlab(\"Hour of day\") +\\\n",
    "    ylab(\"Avg. load1 across all nodes\")\n",
    "\n",
    "plt.save(\"load1_per_hour_of_day_diurnal_15min_bin_1h_window.pdf\")\n",
    "plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, compute the average for the same hours per node, then the mean across all nodes\n",
    "load1_per_node_per_day = bin_df.groupby(\"day\").mean()\n",
    "load1_per_day = load1_per_node_per_day.mean(axis=1).reset_index()\n",
    "load1_per_day.columns = [\"day\", \"load\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt = ggplot(load1_per_day, aes(x=\"day\", y=\"load\")) +\\\n",
    "    theme_light(base_size=16) +\\\n",
    "    theme(axis_text_x = element_text(angle = 45)) +\\\n",
    "    geom_bar(stat = \"identity\") +\\\n",
    "    ylim(0,None) +\\\n",
    "    xlab(\"Day in Week\") +\\\n",
    "    ylab(\"Avg. load1 across all nodes\") +\\\n",
    "    scale_x_continuous(breaks=list(range(0,7)), labels=list(calendar.day_name))\n",
    "\n",
    "plt.save(\"load1_per_day_of_week_diurnal_15min_bin_1h_window.pdf\")\n",
    "plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a series of hour of day -> all values to plot in a violin/boxplot.\n",
    "def get_values(rows):\n",
    "    print(rows.columns)\n",
    "    hour = rows['hour_of_day'].iloc[0]\n",
    "    rows.drop('hour_of_day', axis=1, inplace=True)\n",
    "    arr = rows.to_numpy()\n",
    "    return arr[arr >= 0].ravel()\n",
    "\n",
    "ndf = df.groupby('hour_of_day').apply(get_values)\n",
    "ndf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create per hour a violin boxplot plot\n",
    "plt = ggplot(hour_of_day_df, aes(x=\"hour_of_day\", y=\"values\")) +\\\n",
    "    geom_violin(width=0.2) +\\\n",
    "    geom_boxplot(width=0.1, color=\"grey\", alpha=0.2) +\\\n",
    "    scale_fill_cmap(discrete = True) +\\\n",
    "    theme_light() +\\\n",
    "    theme(\n",
    "      legend_position=\"none\",\n",
    "      plot_title = element_text(size=11)\n",
    "    ) +\\\n",
    "    ggtitle(\"A Violin wrapping a boxplot\") +\\\n",
    "    xlab(\"\")\n",
    "\n",
    "plt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
