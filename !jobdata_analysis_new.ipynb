{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collected job data from Lisa using the following command:\n",
    "# sacct -a --starttime 2020-01-01 --format=jobid,gid,uid,partition,submit,start,end,elapsedraw,cputimeraw,ncpus,nnodes,nodelist,exitcode,state,timelimit > $HOME/jobdata.csv\n",
    "\n",
    "# Required packages for processing\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time, datetime, pytz\n",
    "from matplotlib.ticker import MultipleLocator, FixedLocator, LogLocator, NullFormatter\n",
    "from datetime import date, datetime, time\n",
    "from multiprocessing import cpu_count\n",
    "from pandarallel import pandarallel\n",
    "from mpl_toolkits.axes_grid1.inset_locator import mark_inset\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required preprocessing/parsing of the job data\n",
    "def preprocess_jobdata_to_df(name):\n",
    "    with open(os.path.join(location_job_data_csv, name),'r') as file:\n",
    "        filedata = file.read()\n",
    "        filedata = filedata.replace('None assigned','NoneAssigned')\n",
    "    with open(os.path.join(location_job_data_csv, str('processed_'+name)),'w') as file:\n",
    "        file.write(filedata)\n",
    "    jobdata = pd.read_fwf(os.path.join(location_job_data_csv, str('processed_'+name)), delimiter=r\"\\s+\", header=None)#, low_memory=False)\n",
    "    jobdata = jobdata.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)\n",
    "    jobdata = jobdata.rename(columns=jobdata.iloc[0]).drop(jobdata.index[0])\n",
    "    jobdata = jobdata.iloc[1:]\n",
    "    jobdata = jobdata.astype({\"ElapsedRaw\": int, \"CPUTimeRAW\": int, \"NCPUS\": int})\n",
    "    return(jobdata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import job data\n",
    "location_job_data_csv = \"path to workload\"\n",
    "jobdata = preprocess_jobdata_to_df('jobdata.csv')\n",
    "print(jobdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobdata.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some extra preprocessing required for the job data, e.g. filtering out irrelevant login nodes\n",
    "filtered_jobs = jobdata[(jobdata[\"Start\"] >= '2019-12-29 23:00:00') & (jobdata[\"Start\"] <= '2020-08-07 21:59:45')]\n",
    "filtered_jobs = filtered_jobs[(~filtered_jobs[\"NodeList\"].str.contains(\"None\")) & (~filtered_jobs[\"NodeList\"].str.contains(\"software\")) & (~filtered_jobs[\"NodeList\"].str.contains(\"login\"))]\n",
    "filtered_jobs[\"ElapsedRaw\"] = filtered_jobs[\"ElapsedRaw\"].apply(lambda x: (x / 60) / 60)\n",
    "print(filtered_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a column that indicates if a job was executed on ML nodes \n",
    "gpu_nodes = {\n",
    "    \"r28n1\", \"r28n2\", \"r28n3\", \"r28n4\", \"r28n5\",\n",
    "    \"r29n1\", \"r29n2\", \"r29n3\", \"r29n4\", \"r29n5\",\n",
    "    \"r30n1\", \"r30n2\", \"r30n3\", \"r30n4\", \"r30n5\", \"r30n6\", \"r30n7\",\n",
    "    \"r31n1\", \"r31n2\", \"r31n3\", \"r31n4\", \"r31n5\", \"r31n6\"\n",
    "    \"r32n1\", \"r32n2\", \"r32n3\", \"r32n4\", \"r32n5\", \"r32n6\", \"r32n7\",\n",
    "    \"r33n2\", \"r33n3\", \"r33n5\", \"r33n6\",\n",
    "    \"r34n1\", \"r34n2\", \"r34n3\", \"r34n4\", \"r34n5\", \"r34n6\", \"r34n7\",\n",
    "    \"r35n1\", \"r35n2\", \"r35n3\", \"r35n4\", \"r35n5\",\n",
    "    \"r36n1\", \"r36n2\", \"r36n3\", \"r36n4\", \"r36n5\",\n",
    "    \"r38n1\", \"r38n2\", \"r38n3\", \"r38n4\", \"r38n5\",\n",
    "}\n",
    "\n",
    "def split_nodes(s): # parses node strings like r12n[1-30,32] to r12n1, r12n2 ... r12n30, r12n32\n",
    "    if s is None or len(s) == 0:\n",
    "        return set()\n",
    "    \n",
    "    s = s.replace(\"\\r\\n\", \"\").replace(\"\\n\", \"\").replace(\"\\t\", \"\")\n",
    "\n",
    "    start = 0\n",
    "    index = 0\n",
    "    rack_chunks = []\n",
    "    in_bracket = False\n",
    "    while index < len(s):  # Separate them in parts like r12n[1-30,32] or r13n1\n",
    "        if s[index] == \"[\":\n",
    "            in_bracket = True\n",
    "        elif s[index] == \"]\":\n",
    "            in_bracket = False\n",
    "        elif s[index] == \",\" and not in_bracket:\n",
    "            rack_chunks.append(s[start: index])\n",
    "            start = index + 1\n",
    "        index += 1\n",
    "    rack_chunks.append(s[start: index])  # Add the last line\n",
    "    \n",
    "    node_names = set()\n",
    "\n",
    "    for rack_chunk in rack_chunks:\n",
    "        if \"[\" in rack_chunk:\n",
    "            prefix, postfix = rack_chunk.split(\"[\")\n",
    "            postfix = postfix[:-1]  # Remove the last bracket\n",
    "            nodes = postfix.split(\",\")\n",
    "            for node in nodes:\n",
    "                if \"-\" in node:\n",
    "                    start, end = node.split(\"-\")\n",
    "                    if not start.isnumeric() or not end.isnumeric():\n",
    "                        continue\n",
    "                    for i in range(int(start), int(end) + 1):\n",
    "                        node_names.add(\"{}{}\".format(prefix, i))\n",
    "                else:\n",
    "                    node_names.add(\"{}{}\".format(prefix, node))\n",
    "        else:\n",
    "            node_names.add(rack_chunk)\n",
    "\n",
    "    return node_names\n",
    "\n",
    "def calculate_perjob(row):\n",
    "    nodes = row[\"NodeList\"]\n",
    "    splitnodes = split_nodes(nodes)\n",
    "    return any([n in gpu_nodes for n in splitnodes])\n",
    "\n",
    "pandarallel.initialize(nb_workers=min(cpu_count(), 8), progress_bar=True)\n",
    "filtered_jobs[\"is_gpu\"] =  filtered_jobs.parallel_apply(calculate_perjob, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(df):\n",
    "    df = df.value_counts(sort=False, normalize=True).rename_axis('target').reset_index(name='pdf')\n",
    "    df[\"cdf\"] = df[\"pdf\"].cumsum()\n",
    "    return df\n",
    "\n",
    "completed_elapsed_values = filtered_jobs[filtered_jobs['State'] == \"COMPLETED\"]\n",
    "all_values_df = pd.DataFrame({\"target\": completed_elapsed_values[\"ElapsedRaw\"].values * 3600})\n",
    "count_df = normalize(all_values_df)\n",
    "\n",
    "# Print how many jobs are <= duration in seconds\n",
    "duration = 300\n",
    "print(count_df[count_df['target'].le(duration) | np.isclose(count_df['target'], duration, rtol=1e-10, atol=1e-12)].tail(1)['cdf'].iloc[0])\n",
    "    \n",
    "# Generate array containing counts of job lenght \n",
    "counts = np.unique(completed_elapsed_values[\"ElapsedRaw\"].values, return_counts=True)\n",
    "pdf = counts[1] / np.sum(counts[1])\n",
    "cdf = np.cumsum(pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results\n",
    "fig = plt.figure()\n",
    "plt.yscale(\"log\")\n",
    "plt.locator_params(axis='y', numticks=12)\n",
    "plt.bar(counts[0], counts[1], width=1)\n",
    "plt.xlabel(\"Job duration (hours)\")\n",
    "plt.ylabel(\"Jobs\")\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"job_duration_count.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate PDF/CDF\n",
    "pdf = counts[1] / np.sum(counts[1])\n",
    "cdf = np.cumsum(pdf)\n",
    "fig = plt.figure()\n",
    "\n",
    "plt.ylim(0,1.05)\n",
    "plt.plot(counts[0], cdf, drawstyle='steps')\n",
    "plt.xscale(\"log\")\n",
    "plt.xlabel(\"Job duration (hours)\")\n",
    "plt.ylabel(\"Fraction of total jobs\")\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"job_duration_cdf.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(11,4))\n",
    "\n",
    "ax1.tick_params(axis='both', which='major', labelsize=18)\n",
    "ax1.tick_params(axis='both', which='minor', labelsize=18)\n",
    "\n",
    "ax1.set_xlabel('Job Duration [Hour]', fontsize=20)\n",
    "ax1.set_ylabel('PDF', color='lightcoral', fontsize=20)\n",
    "plt.ylim(-0.05,1.05)\n",
    "plt.xscale(\"log\")\n",
    "ax1.plot(counts[0], pdf, color='lightcoral', drawstyle='steps')\n",
    "ax1.tick_params(axis='y', labelcolor='lightcoral')\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "ax2.tick_params(axis='both', which='major', labelsize=18)\n",
    "ax2.tick_params(axis='both', which='minor', labelsize=18)\n",
    "\n",
    "color = 'steelblue'\n",
    "ax2.set_ylabel('CDF - Fraction of\\nCompleted Jobs', color=color, fontsize=20)\n",
    "ax2.plot(counts[0], cdf, color=color, drawstyle='steps')\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "plt.ylim(-0.05,1.05)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "date_time = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "fig.savefig(f\"job_duration_cdf_pdf_{date_time}.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate array containing counts of cpu core allocation for jobs \n",
    "counts_cpus = np.unique(filtered_jobs[\"NCPUS\"].values, return_counts=True)\n",
    "print(counts_cpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results\n",
    "fig, ax = plt.subplots(figsize=(11,5))\n",
    "\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_ylim(bottom=1)\n",
    "ax.set_ylim(top=10**6.5)\n",
    "ax.bar(counts_cpus[0], counts_cpus[1], width=1, color=\"lightcoral\")\n",
    "ax.set_xlabel(\"CPU Cores in Job\", fontsize=20)\n",
    "\n",
    "majors = [0, 100, 200, 300, 400, 500, 600]\n",
    "ax.xaxis.set_major_locator(FixedLocator(majors))\n",
    "ax.xaxis.set_minor_locator(FixedLocator((np.arange(min(counts_cpus[0]-1), 600, 10))))\n",
    "ax.tick_params(axis='both', which='major', labelsize=16)\n",
    "ax.tick_params(axis='both', which='minor', labelsize=16)\n",
    "\n",
    "plt.ylabel(\"Jobs\", fontsize=20)\n",
    "plt.tight_layout()\n",
    "\n",
    "a = plt.axes([.505, .5, .45, .41], facecolor='lightgrey')\n",
    "a.set_ylim(bottom=1, top=10**6.45)\n",
    "a.bar(counts_cpus[0][0:23], counts_cpus[1][0:23], width=0.3, color=\"lightcoral\")\n",
    "a.set_title('Zoomed-in view', fontsize=18)\n",
    "a.set_yscale(\"log\")\n",
    "majors_2 = [0, 10, 20, 30, 40, 50]\n",
    "a.xaxis.set_major_locator(FixedLocator(majors_2))\n",
    "a.xaxis.set_minor_locator(FixedLocator((np.arange(min(counts_cpus[0]-1), 50, 1))))\n",
    "a.tick_params(axis='both', which='major', labelsize=15)\n",
    "a.tick_params(axis='both', which='minor', labelsize=15)\n",
    "\n",
    "mark_inset(ax, a, loc1=3, loc2=4, fc=\"none\", ec=\"steelblue\")\n",
    "\n",
    "\n",
    "date_time = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "fig.savefig(f\"job_cpus_count_zoom_{date_time}.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot PDF/CDF\n",
    "pdf = counts_cpus[1] / np.sum(counts_cpus[1])\n",
    "cdf = np.cumsum(pdf)\n",
    "fig = plt.figure()\n",
    "plt.ylim(0,1.05)\n",
    "plt.plot(counts_cpus[0], cdf, drawstyle='steps')\n",
    "plt.xscale(\"symlog\")\n",
    "plt.xlabel(\"CPU cores in job\")\n",
    "plt.ylabel(\"Fraction of total jobs\")\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"job_cpus_cdf.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note there seems to be some issue with the plotting library, which does not seem to show every first \n",
    "# minor tick after a major tick on log/symlog scales, even when this is hard-coded like below\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "ax1.set_xlabel('Number of cores in job')\n",
    "ax1.set_ylabel('PDF')\n",
    "plt.ylim(-0.05,1.05)\n",
    "plt.xscale(\"symlog\", subsx = [1,2,3,4,5,6,7,8,9])\n",
    "ax1.plot(counts_cpus[0], pdf, color='black', drawstyle='steps')\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax2.set_ylabel('CDF - Fraction of total jobs', color=color)\n",
    "ax2.plot(counts_cpus[0], cdf, color=color, drawstyle='steps')\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "plt.ylim(-0.05,1.05)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig(\"job_cpus_cdf_pdf.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_date = jobdata[(jobdata[\"Start\"] >= '2019-12-29 23:00:00') & (jobdata[\"Start\"] <= '2020-08-07 21:59:45')]\n",
    "group_date = group_date[(~group_date[\"NodeList\"].str.contains(\"None\")) & (~group_date[\"NodeList\"].str.contains(\"software\")) & (~group_date[\"NodeList\"].str.contains(\"login\"))]\n",
    "group_date[\"squashed_area\"] = group_date[\"ElapsedRaw\"] * group_date[\"NCPUS\"]\n",
    "group_date[\"Submit\"] = pd.to_datetime(group_date[\"Submit\"], utc=True)\n",
    "group_date = group_date.set_index(\"Submit\")\n",
    "daily_squashed_area = group_date['squashed_area'].resample('D').sum()\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.yscale(\"log\")\n",
    "plt.ylim(bottom=1)\n",
    "plt.ylim(top=10**9.5)\n",
    "plt.locator_params(axis='y', numticks=12)\n",
    "plt.bar(datelist, daily_squashed_area, width=1)\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"CPU-Hours\")\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"job_squashed_area.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax, ax2) = plt.subplots(2, 1, sharex=True)\n",
    "\n",
    "# plot the same data on both axes\n",
    "ax.bar(datelist, daily_squashed_area, width=1)\n",
    "ax2.bar(datelist, daily_squashed_area, width=1)\n",
    "\n",
    "ax.set_yscale(\"log\")\n",
    "ax2.set_yscale(\"log\")\n",
    "\n",
    "# zoom-in / limit the view to different portions of the data\n",
    "ax.set_ylim(10**7,10**9.25)\n",
    "ax2.set_ylim(10**0, 10**3)\n",
    "\n",
    "# hide the spines between ax and ax2\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax2.spines['top'].set_visible(False)\n",
    "ax2.xaxis.tick_bottom()\n",
    "\n",
    "d = .015  # how big to make the diagonal lines in axes coordinates\n",
    "# arguments to pass to plot, just so we don't keep repeating them\n",
    "kwargs = dict(transform=ax.transAxes, color='k', clip_on=False)\n",
    "ax.plot((-d, +d), (-d, +d), **kwargs)        # top-left diagonal\n",
    "ax.plot((1 - d, 1 + d), (-d, +d), **kwargs)  # top-right diagonal\n",
    "\n",
    "kwargs.update(transform=ax2.transAxes)  # switch to the bottom axes\n",
    "ax2.plot((-d, +d), (1 - d, 1 + d), **kwargs)  # bottom-left diagonal\n",
    "ax2.plot((1 - d, 1 + d), (1 - d, 1 + d), **kwargs)  # bottom-right diagonal\n",
    "\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"CPU-Hours\")\n",
    "plt.tight_layout()\n",
    "f.savefig(\"job_squashed_area_split.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate list of dates in dataset, again excluding any login nodes from the data\n",
    "group_date = filtered_jobs.copy()\n",
    "group_date[\"Submit\"] = pd.to_datetime(group_date[\"Submit\"], utc=True)\n",
    "group_date = group_date.set_index(\"Submit\")\n",
    "group_date = group_date.groupby([group_date.index.date, \"is_gpu\"]).count().unstack(1)\n",
    "datelist = list(group_date.index.values) \n",
    "submissionlist = group_date[\"JobID\"].fillna(0)  # just grab one column as all columns have the same counts\n",
    "submissionlist.columns = ['generic', 'ml']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submissionlist.sum(axis=1).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_max_value = submissionlist.sum(axis=1).idxmax()\n",
    "max_val = submissionlist.loc[date_max_value].sum()\n",
    "print(date_max_value, max_val)\n",
    "print(\"{:,}\".format(max_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(11,5))\n",
    "plt.yscale(\"symlog\", subsy = [1,2,3,4,5,6,7,8,9])\n",
    "plt.ylim(bottom=1)\n",
    "plt.ylim(top=5.5 * 10**5)\n",
    "plt.locator_params(axis='y', numticks=12)\n",
    "ax.bar(datelist, submissionlist.sum(axis=1), width=1, color=\"lightcoral\")\n",
    "ax.bar(datelist, submissionlist['ml'], width=1, color=\"steelblue\")  # Plot ML jobs overlapping\n",
    "plt.xlabel(\"Date\", fontsize=22)\n",
    "plt.ylabel(\"Job Submissions\", fontsize=22)\n",
    "ax.tick_params(axis='both', which='major', labelsize=18)\n",
    "ax.tick_params(axis='both', which='minor', labelsize=18)\n",
    "\n",
    "date_max_value = submissionlist.sum(axis=1).idxmax()\n",
    "max_value = submissionlist.loc[date_max_value].sum()\n",
    "ax.annotate(\"{:,}\".format(int(max_value)),\n",
    "            xy=(date_max_value, max_value), xycoords='data',\n",
    "            xytext=(20, 0), textcoords='offset points',\n",
    "            fontsize=18,\n",
    "            arrowprops=dict(arrowstyle=\"->\",\n",
    "                            connectionstyle=\"arc\"\n",
    "                           )\n",
    "            )\n",
    "\n",
    "annotate_date = submissionlist.sum(axis=1).sort_values().index[-3]\n",
    "annotate_value_all_jobs = submissionlist.sum(axis=1).loc[annotate_date]\n",
    "annotate_value_ml_jobs = submissionlist['ml'].loc[annotate_date]\n",
    "\n",
    "ax.annotate(\"All jobs\",\n",
    "            xy=(annotate_date, annotate_value_all_jobs), xycoords='data',\n",
    "            xytext=(20, 0), textcoords='offset points',\n",
    "            fontsize=18,\n",
    "            arrowprops=dict(arrowstyle=\"->\",\n",
    "                            connectionstyle=\"arc\"\n",
    "                           )\n",
    "            )\n",
    "\n",
    "ax.annotate(\"ML jobs\",\n",
    "            xy=(annotate_date, annotate_value_ml_jobs), xycoords='data',\n",
    "            xytext=(20, -25), textcoords='offset points',\n",
    "            fontsize=18, color=\"white\",\n",
    "            arrowprops=dict(arrowstyle=\"->\",\n",
    "                            connectionstyle=\"arc\",\n",
    "                            color=\"white\"\n",
    "                           )\n",
    "            )\n",
    "\n",
    "combined = submissionlist.sum(axis=1)\n",
    "median = combined.median()\n",
    "median_zeroes_filtered = combined[combined > 0].median()\n",
    "median_ml_jobs = submissionlist['ml'].median()\n",
    "avg = combined.mean()\n",
    "ax.axhline(avg, label=\"Average ({:,.0f})\".format(avg), color=\"yellowgreen\", linestyle=\"solid\")\n",
    "ax.axhline(median, label=\"Median ({:,})\".format(int(median)), color=\"orchid\", linestyle=\"dashed\")\n",
    "ax.axhline(median_zeroes_filtered, label=\"Median zeros filtered ({:,})\".format(int(median_zeroes_filtered)), color=\"gold\", linestyle=\"dotted\")\n",
    "ax.axhline(median_ml_jobs, label=\"Median ML ({:,})\".format(int(median_ml_jobs)), color=\"black\", linestyle=\"dashdot\")\n",
    "ax.legend(ncol=2, prop={\"size\": 18}, bbox_to_anchor=(0.5, 1.35), loc=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "date_time = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "fig.savefig(f\"job_submission_count_{date_time}.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
